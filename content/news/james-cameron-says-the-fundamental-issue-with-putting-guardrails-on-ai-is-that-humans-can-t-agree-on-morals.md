---
title: "James Cameron says the 'fundamental issue' with putting guardrails on AI is that humans can't agree on morals"
date: 2026-01-01
description: "Director James Cameron appeared on the &quot;Just Foolin&apos; About&quot; podcast on Dec. 23, where he argued that putting guardrails on AI is nearly impossible because humans can&apos;t agree on morals."
summary: "Director James Cameron appeared on the &quot;Just Foolin&apos; About&quot; podcast on Dec. 23, where he argued that putting guardrails on AI is nearly impossible because humans can&apos;t agree on morals."
slug: "james-cameron-says-the-fundamental-issue-with-putting-guardrails-on-ai-is-that-humans-can-t-agree-on-morals"
image: ''
link: 'https://www.foxnews.com/media/james-cameron-says-fundamental-issue-putting-guardrails-ai-humans-cant-agree-morals'
source: 'https://feeds.foxnews.com/foxnews/latest'
categories:
- 'feeds.foxnews.com'
tags:
- 'fundamental'
- 'guardrails'
- 'cameron'
- 'putting'
- 'humans'

draft: false
---
<p>"Avatar" director James Cameron argued that the "fundamental issue" in creating guardrails for <a href="https://www.foxnews.com/category/tech/artificial-intelligence" target="_blank" rel="noopener">artificial intelligence</a> is that humans can't agree on morals, noting that finding a universal moral code is nearly impossible.</p><p>During an appearance on "Just Foolin' About with Michael Biehn" last week, <a href="https://www.youtube.com/watch?v=8vEYRARBXxk" target="_blank" rel="nofollow noopener">Cameron argued</a> that morality is subjective, pointing out that religions and political systems adhere to different moral frameworks, making consensus difficult to achieve.</p><p>"The fundamental problem is — they call it ‘alignment,’ right? You have this artificial superintelligence. As long as it is aligned with human good, then it won't betray us, it won't turn against us, it'll only improve our lives, right?" he explained. "Except, the big fundamental problem is that we can't agree on one godd--- thing about what is best for human beings."</p><p><a href="https://www.foxnews.com/media/sanders-says-science-fiction-fear-ai-running-world-not-quite-so-outrageous" target="_blank" rel="noopener"><strong>SANDERS SAYS 'SCIENCE-FICTION FEAR' OF AI RUNNING THE WORLD 'NOT QUITE SO OUTRAGEOUS'</strong></a></p><p>Cameron added that by creating guardrails to constrain AI, what humans are actually doing is "trying to impose morality on a conscious system that's smarter than us," but also looks to humans as its "parents to give it moral guidelines."</p><p>The issue with creating these guardrails, according to Cameron, is that "everybody's morality is different," which inevitably leads to disagreement over which moral framework would be best suited to keep AI in line.</p><p><a href="https://www.foxnews.com/media/kevin-oleary-warns-china-kicking-our-heinies-ai-race-regulatory-roadblocks-stall-us" target="_blank" rel="noopener"><strong>KEVIN O'LEARY WARNS CHINA 'KICKING OUR HEINIES' IN AI RACE AS REGULATORY ROADBLOCKS STALL US</strong></a></p><p>Aside from his concerns over how to properly regulate AI, Cameron has also been vocal about how he feels about the technology in terms of assisting in the production of movies.</p><p>Originally a skeptic, Cameron denounced the use of AI in films in 2023, saying he believed "the weaponization of AI is the biggest danger."</p><p>"I think that we will get into the equivalent of a nuclear arms race with AI, and if we don't build it, the other guys are for sure going to build it, and so then it'll escalate," Cameron said at the time.</p><p><a href="https://www.foxnews.com/media" target="_blank" rel="noopener"><strong><u>CLICK HERE FOR MORE COVERAGE OF MEDIA AND CULTURE</u></strong></a></p><p>Cameron's stance on AI <a href="https://www.foxnews.com/entertainment/terminator-director-james-cameron-flip-flops-ai-says-hollywood-looking-all-wrong" target="_blank" rel="noopener">has evolved in recent years</a>, and he now says that Hollywood needs to embrace the technology in several different ways.</p><p>Cameron joined the board of directors for Stability AI last year, explaining his decision on the "Boz to the Future" podcast in April.</p><p>"The goal was to understand the space, to understand what’s on the minds of the developers," he said. "What are they targeting? What’s their development cycle? How much resources you have to throw at it to create a new model that does a purpose-built thing, and my goal was to try to integrate it into a VFX workflow." </p><p>He continued by saying the shift to AI is a necessary one.</p><p>"And it’s not just hypothetical. We have to. If we want to continue to see the kinds of movies that I’ve always loved and that I like to make and that I will go to see – ‘Dune,’ ‘Dune: Part Two’ or one of my films or big effects-heavy, CG-heavy films – we’ve got to figure out how to cut the cost of that in half.</p><p>"Now that’s not about laying off half the staff at a VFX company. That’s about doubling their speed to completion on a given shot, so your cadence is faster and your throughput cycle is faster, and artists get to move on and do other cool things and then other cool things, right? That’s my sort of vision for that."</p><p><i>Fox News' Elizabeth Stanton contributed to this report.</i></p>
